import re
from typing import List, Dict, Any, Tuple

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.multioutput import MultiOutputClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MultiLabelBinarizer

# ============================================================
# 1. –ò–ú–ü–û–†–¢ –î–ê–¢–ê–°–ï–¢–ê
# ============================================================
# –û–∂–∏–¥–∞–µ—Ç—Å—è, —á—Ç–æ –≤ model/data.py –µ—Å—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è:
# data = [
#   {
#       "text": "...",
#       "job_role": "—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫" / "–∞–Ω–∞–ª–∏—Ç–∏–∫" / ... (–º–æ–∂–µ—Ç –±—ã—Ç—å None),
#       "skills": ["python", "django", ...] (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ),
#       "experience_level": "junior/middle/senior/lead" (–º–æ–∂–µ—Ç –±—ã—Ç—å None),
#       "work_format": "–æ—Ñ–∏—Å/—É–¥–∞–ª—ë–Ω–∫–∞/–≥–∏–±—Ä–∏–¥/..." (–º–æ–∂–µ—Ç –±—ã—Ç—å None),
#       "salary_min": 180000 (–º–æ–∂–µ—Ç –±—ã—Ç—å None),
#       "company_field": "it/—Ñ–∏–Ω–∞–Ω—Å—ã/..." (–º–æ–∂–µ—Ç –±—ã—Ç—å None),
#   },
#   ...
# ]
from model.data import data


# ============================================================
# 2. –°–õ–û–í–ê–†–ò –°–ò–ù–û–ù–ò–ú–û–í / –ü–û–î–°–ö–ê–ó–ö–ò
# ============================================================

# ‚Äî –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —ç–≤—Ä–∏—Å—Ç–∏–∫ (–∫—Ä–æ–º–µ ML)
JOB_TITLE_HEADER_PATTERNS = [
    r"–≤–∞–∫–∞–Ω—Å–∏—è[:\- ]+(.*)",
    r"–ø–æ–∑–∏—Ü–∏—è[:\- ]+(.*)",
    r"–∏—â–µ–º[:\- ]+(.*)",
    r"—Ç—Ä–µ–±—É–µ—Ç—Å—è[:\- ]+(.*)",
    r"we are looking for[:\- ]+(.*)",
    r"we‚Äôre hiring[:\- ]+(.*)",
]

JOB_ROLE_KEYWORDS = {
    "Backend Developer": [
        "backend", "back-end", "–±—ç–∫–µ–Ω–¥", "server-side",
        "python developer", "backend developer", "backend engineer"
    ],
    "Frontend Developer": [
        "frontend", "front-end", "—Ñ—Ä–æ–Ω—Ç–µ–Ω–¥", "react developer",
        "javascript developer", "ui developer"
    ],
    "Fullstack Developer": [
        "fullstack", "full-stack", "full stack", "—Ñ—É–ª–ª—Å—Ç–µ–∫"
    ],
    "DevOps Engineer": [
        "devops", "dev ops", "sre", "site reliability"
    ],
    "Data Scientist": [
        "data scientist", "data science", "ml engineer", "machine learning engineer"
    ],
    "Data Analyst": [
        "data analyst", "–∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö", "product analyst", "bi analyst"
    ],
    "QA Engineer": [
        "qa", "qa engineer", "test engineer", "—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫"
    ],
    "UI/UX Designer": [
        "designer", "ui/ux", "ux designer", "product designer", "–¥–∏–∑–∞–π–Ω–µ—Ä"
    ],
    "Product Manager": [
        "product manager", "–ø—Ä–æ–¥–∞–∫—Ç –º–µ–Ω–µ–¥–∂–µ—Ä", "product owner"
    ],
    "Project Manager": [
        "project manager", "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞", "pm"
    ],
}

# ‚Äî –ø–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ —É—Ä–æ–≤–Ω—é
EXPERIENCE_HINTS = {
    "junior": ["junior", "–¥–∂—É–Ω–∏–æ—Ä", "–Ω–∞—á–∏–Ω–∞—é—â–∏–π", "—Å—Ç–∞–∂–µ—Ä", "–∏–Ω—Ç–µ—Ä–Ω–∞—Ç—É—Ä–∞"],
    "middle": ["middle", "–º–∏–¥–ª", "middle+", "middle-"],
    "senior": ["senior", "—Å–µ–Ω—å–æ—Ä", "—Å—Ç–∞—Ä—à–∏–π"],
    "lead": ["lead", "team lead", "tech lead", "–≤–µ–¥—É—â–∏–π", "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å"],
}

# ‚Äî –ø–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É —Ä–∞–±–æ—Ç—ã
REMOTE_WORDS = [
    "—É–¥–∞–ª–µ–Ω–Ω–æ", "—É–¥–∞–ª—ë–Ω–Ω–æ", "remote", "—Ä–∞–±–æ—Ç–∞ –∏–∑ –¥–æ–º–∞", "home office",
    "–ø–æ–ª–Ω–æ—Å—Ç—å—é —É–¥–∞–ª", "full remote"
]
OFFICE_WORDS = [
    "–æ—Ñ–∏—Å", "–≤ –æ—Ñ–∏—Å–µ", "–æ—Ñ–∏—Å –≤", "office"
]
HYBRID_WORDS = [
    "–≥–∏–±—Ä–∏–¥", "hybrid", "—á–∞—Å—Ç–∏—á–Ω–æ —É–¥–∞–ª–µ–Ω–Ω–æ", "—á–∞—Å—Ç–∏—á–Ω–æ —É–¥–∞–ª—ë–Ω–Ω–æ",
    "–Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –≤ –æ—Ñ–∏—Å–µ", "3 –¥–Ω—è –æ—Ñ–∏—Å", "–æ—Ñ–∏—Å/—É–¥–∞–ª–µ–Ω–Ω–æ", "–æ—Ñ–∏—Å + —É–¥–∞–ª–µ–Ω–Ω–æ",
]

# ‚Äî —Å–∏–Ω–æ–Ω–∏–º—ã –Ω–∞–≤—ã–∫–æ–≤ (–¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –∫ ML)
SKILL_SYNONYMS = {
    # Backend
    "python": ["python", "py", "python3", "python 3"],
    "fastapi": ["fastapi", "fast api", "fast-api"],
    "django": ["django"],
    "flask": ["flask"],
    "celery": ["celery"],
    "aiohttp": ["aiohttp", "aio http"],
    "postgresql": ["postgresql", "postgres", "pgsql"],
    "mysql": ["mysql"],
    "redis": ["redis"],
    "rabbitmq": ["rabbitmq", "rabbit mq"],
    "mongodb": ["mongodb", "mongo"],

    # Frontend
    "react": ["react", "reactjs", "react.js"],
    "typescript": ["typescript", "ts"],
    "javascript": ["javascript", "js"],
    "redux": ["redux"],
    "mobx": ["mobx"],
    "next.js": ["next.js", "next js", "nextjs"],
    "node.js": ["node.js", "nodejs", "node js"],
    "css": ["css", "css3"],
    "html": ["html", "html5"],
    "webpack": ["webpack"],
    "vite": ["vite"],
    "spa": ["spa", "single page application"],

    # DevOps
    "docker": ["docker"],
    "kubernetes": ["kubernetes", "k8s"],
    "terraform": ["terraform"],
    "ansible": ["ansible"],
    "jenkins": ["jenkins"],
    "gitlab ci": ["gitlab ci", "gitlab-ci", "gitlabci"],
    "grafana": ["grafana"],
    "prometheus": ["prometheus"],
    "elk": ["elk", "elk stack"],

    # Data / ML
    "pandas": ["pandas"],
    "numpy": ["numpy"],
    "scikit-learn": ["scikit-learn", "sklearn"],
    "tensorflow": ["tensorflow", "tf"],
    "pytorch": ["pytorch"],
    "xgboost": ["xgboost"],
    "machine learning": ["machine learning", "ml"],
    "sql": ["sql"],

    # Tools
    "git": ["git"],
    "jira": ["jira"],
    "confluence": ["confluence"],
    "linux": ["linux"],
}


# ============================================================
# 3. –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ============================================================

def _normalize_list_field(series, default_empty=True) -> pd.Series:
    """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ ‚Äî —Å–ø–∏—Å–æ–∫ (–¥–ª—è skills)."""
    cleaned = []
    for v in series:
        if isinstance(v, list):
            cleaned.append(v)
        elif pd.isna(v):
            cleaned.append([] if default_empty else [None])
        else:
            cleaned.append([v])
    return pd.Series(cleaned)


def _extract_header_job_title(text: str) -> str | None:
    """–ü—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å –¥–æ–ª–∂–Ω–æ—Å—Ç—å –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ '–í–∞–∫–∞–Ω—Å–∏—è: ...', '–ò—â–µ–º ...' –∏ —Ç.–ø."""
    for pattern in JOB_TITLE_HEADER_PATTERNS:
        m = re.search(pattern, text, flags=re.IGNORECASE)
        if m:
            role = m.group(1).strip()
            role = role.split("\n")[0].strip()
            role = re.sub(r"\(.*?\)", "", role).strip()
            return role if len(role) > 2 else None
    return None


def _extract_job_role_smart(text: str) -> str | None:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–ª–∂–Ω–æ—Å—Ç—å –∏–∑ —Ç–µ–∫—Å—Ç–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ.
    –†–∞–±–æ—Ç–∞–µ—Ç –ø–æ —à–∞–±–ª–æ–Ω–∞–º, –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –∏ —Å–æ–∫—Ä–∞—â–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã.
    """

    t = text.lower()

    # --- 1) –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞:
    # "–ò—â–µ–º Frontend —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞", "–¢—Ä–µ–±—É–µ—Ç—Å—è Senior Backend Developer"
    header_patterns = [
        r"(?:–≤–∞–∫–∞–Ω—Å–∏—è[:\- ]+)(.+)",
        r"(?:–∏—â–µ–º[:\- ]+)(.+)",
        r"(?:—Ç—Ä–µ–±—É–µ—Ç—Å—è[:\- ]+)(.+)",
        r"(?:–º—ã –∏—â–µ–º[:\- ]+)(.+)",
        r"(?:we are looking for[:\- ]+)(.+)",
        r"(?:we‚Äôre hiring[:\- ]+)(.+)"
    ]

    for pat in header_patterns:
        m = re.search(pat, text, flags=re.IGNORECASE)
        if m:
            role = m.group(1).strip()
            # —É–±–∏—Ä–∞–µ–º –≤—Å—ë –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –¥–µ—Ñ–∏—Å–∞/—Ç–æ—á–∫–∏
            role = re.split(r"[.,;!]| –¥–ª—è | —á—Ç–æ–±—ã ", role)[0].strip()
            if 3 <= len(role) <= 60:
                return role

    # --- 2) –ü—Ä—è–º—ã–µ —à–∞–±–ª–æ–Ω—ã –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π
    ROLE_PATTERNS = [
        r"(senior\s+[a-z–∞-—è0-9\- ]+developer)",
        r"(middle\s+[a-z–∞-—è0-9\- ]+developer)",
        r"(junior\s+[a-z–∞-—è0-9\- ]+developer)",
        r"([a-z–∞-—è0-9\- ]+developer)",
        r"([a-z–∞-—è ]+—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫)",
        r"(team lead [a-z–∞-—è ]+)",
        r"(tech lead [a-z–∞-—è ]+)",
        r"([a-z–∞-—è ]+analyst)",
        r"([a-z–∞-—è ]+–∏–Ω–∂–µ–Ω–µ—Ä)",
    ]

    for pat in ROLE_PATTERNS:
        m = re.search(pat, t, flags=re.IGNORECASE)
        if m:
            role = m.group(1).strip()
            role = re.split(r"[.,;!]| –¥–ª—è | —á—Ç–æ–±—ã ", role)[0].strip()
            # –ö–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è
            return role.capitalize()

    return None


def _heuristic_experience(text: str, ml_pred: List[str]) -> str:
    """–ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º ML-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏ —ç–≤—Ä–∏—Å—Ç–∏–∫—É –ø–æ —Å–ª–æ–≤–∞–º/–≥–æ–¥–∞–º."""
    if ml_pred:
        return ml_pred[0]

    t = text.lower()

    # –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    for lvl, kws in EXPERIENCE_HINTS.items():
        if any(kw in t for kw in kws):
            return lvl

    # –ø–æ –≥–æ–¥–∞–º –æ–ø—ã—Ç–∞
    m = re.search(r"–æ–ø—ã—Ç.*?(\d+)\s*–≥–æ–¥", t)
    if m:
        years = int(m.group(1))
        if years <= 1:
            return "junior"
        elif 2 <= years <= 3:
            return "middle"
        elif 4 <= years <= 5:
            return "senior"
        else:
            return "lead"

    return "–Ω–µ —É–∫–∞–∑–∞–Ω"


def _heuristic_work_format(text: str, ml_pred: List[str]) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã, —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º '–≥–∏–±—Ä–∏–¥', –µ—Å–ª–∏ —è–≤–Ω–æ –∏ –æ—Ñ–∏—Å, –∏ —É–¥–∞–ª—ë–Ω–∫–∞."""
    t = text.lower()

    has_remote = any(w in t for w in REMOTE_WORDS)
    has_office = any(w in t for w in OFFICE_WORDS)
    has_hybrid_word = any(w in t for w in HYBRID_WORDS)

    # 1. –Ø–≤–Ω—ã–π –≥–∏–±—Ä–∏–¥ –ø–æ —Å–ª–æ–≤–∞–º
    if has_hybrid_word or (has_remote and has_office):
        return "–≥–∏–±—Ä–∏–¥"

    # 2. –ï—Å–ª–∏ ML —á—Ç–æ-—Ç–æ –Ω–∞—à—ë–ª ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º
    if ml_pred:
        return ml_pred[0]

    # 3. fallback –ø–æ –∫–ª—é—á–∞–º
    if has_remote and not has_office:
        return "—É–¥–∞–ª—ë–Ω–∫–∞"
    if has_office and not has_remote:
        return "–æ—Ñ–∏—Å"

    return "–Ω–µ —É–∫–∞–∑–∞–Ω"


def _extract_skills_by_synonyms(text: str) -> List[str]:
    """–î–æ—Å—Ç–∞—ë–º –Ω–∞–≤—ã–∫–∏ –ø–æ —Å–ª–æ–≤–∞—Ä—é —Å–∏–Ω–æ–Ω–∏–º–æ–≤."""
    t = text.lower()
    found = []
    for canonical, synonyms in SKILL_SYNONYMS.items():
        if any(s in t for s in synonyms):
            found.append(canonical)
    return sorted(set(found))


def _extract_salary(text: str) -> Tuple[int | None, int | None]:
    """
    –ê–∫–∫—É—Ä–∞—Ç–Ω–æ –¥–æ—Å—Ç–∞—ë–º –∑–∞—Ä–ø–ª–∞—Ç—É:
    - –¥–∏–∞–ø–∞–∑–æ–Ω: 180000‚Äì220000, 180 000 - 220 000, –æ—Ç 180000 –¥–æ 220000
    - –æ—Ç X
    """
    t = text.lower()

    # –£–±–µ—Ä—ë–º –ø—Ä–æ–±–µ–ª—ã –≤–Ω—É—Ç—Ä–∏ —á–∏—Å–µ–ª, –Ω–æ –Ω–µ –≤–æ–∫—Ä—É–≥ "–ª–µ—Ç"
    def _clean_num(s: str) -> int:
        return int(s.replace(" ", "").replace("\u00a0", ""))

    # 1) –î–∏–∞–ø–∞–∑–æ–Ω: –æ—Ç 180 000 –¥–æ 240 000 / 180000‚Äì240000 / 180000-240000
    range_patterns = [
        r"–æ—Ç\s*(\d[\d\s]{3,7})\s*–¥–æ\s*(\d[\d\s]{3,7})",
        r"(\d[\d\s]{3,7})\s*[‚Äì‚Äî-]\s*(\d[\d\s]{3,7})\s*(?:—Ä—É–±|—Ä|—Ä—É–±–ª–µ–π)?",
    ]
    for pat in range_patterns:
        m = re.search(pat, t)
        if m:
            n1, n2 = _clean_num(m.group(1)), _clean_num(m.group(2))
            # —Ñ–∏–ª—å—Ç—Ä –ø—Ä–æ—Ç–∏–≤ "1‚Äì2 –ª–µ—Ç"
            if n1 < 10000 and n2 < 10000:
                continue
            return min(n1, n2), max(n1, n2)

    # 2) "–∑–∞—Ä–ø–ª–∞—Ç–∞ –æ—Ç 180000", "–æ—Ç 200 000 —Ä—É–±."
    m = re.search(r"–æ—Ç\s*(\d[\d\s]{3,7})\s*(?:—Ä—É–±|—Ä|—Ä—É–±–ª–µ–π)?", t)
    if m:
        n = _clean_num(m.group(1))
        if n >= 10000:
            return n, None

    # 3) –û–¥–∏–Ω–æ—á–Ω–æ–µ —á–∏—Å–ª–æ, –ø–æ—Ö–æ–∂–µ–µ –Ω–∞ –∑–∞—Ä–ø–ª–∞—Ç—É
    m = re.search(r"(\d[\d\s]{4,7})\s*(?:—Ä—É–±|—Ä|—Ä—É–±–ª–µ–π)?", t)
    if m:
        n = _clean_num(m.group(1))
        if n >= 40000:
            return n, None

    return None, None


# ============================================================
# 4. –ö–õ–ê–°–° –ú–û–î–ï–õ–ò
# ============================================================

class VacancyModel:
    """
    –ì–∏–±—Ä–∏–¥–Ω–∞—è –º–æ–¥–µ–ª—å:
    - ML (TF-IDF + LogisticRegression + MultiOutputClassifier) –ø–æ:
        * experience_level
        * work_format
        * company_field
        * skills
    - rule-based –ø–æ:
        * job_role
        * salary
        * –¥–æ—É—Ç–æ—á–Ω–µ–Ω–∏–µ work_format/experience
    """

    _pipeline: Pipeline | None = None
    _label_columns: List[str] | None = None

    _exp_labels: List[str] = []
    _fmt_labels: List[str] = []
    _field_labels: List[str] = []
    _skill_labels: List[str] = []

    @classmethod
    def _train_if_needed(cls):
        if cls._pipeline is not None:
            return

        df = pd.DataFrame(data)

        if "text" not in df:
            raise ValueError("–í –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–µ—Ç –ø–æ–ª—è 'text'")

        df["text"] = df["text"].astype(str)

        # ----- experience_level -----
        if "experience_level" in df:
            df["experience_level"] = df["experience_level"].fillna("").astype(str).str.strip()
            exp_y = pd.get_dummies(df["experience_level"], prefix="exp")
            cls._exp_labels = sorted(
                [c.split("exp_")[1] for c in exp_y.columns if c != "exp_"]
            )
        else:
            exp_y = pd.DataFrame(index=df.index)
            cls._exp_labels = []

        # ----- work_format -----
        if "work_format" in df:
            df["work_format"] = df["work_format"].fillna("").astype(str).str.strip()
            fmt_y = pd.get_dummies(df["work_format"], prefix="fmt")
            cls._fmt_labels = sorted(
                [c.split("fmt_")[1] for c in fmt_y.columns if c != "fmt_"]
            )
        else:
            fmt_y = pd.DataFrame(index=df.index)
            cls._fmt_labels = []

        # ----- company_field -----
        if "company_field" in df:
            df["company_field"] = df["company_field"].fillna("").astype(str).str.strip()
            field_y = pd.get_dummies(df["company_field"], prefix="fld")
            cls._field_labels = sorted(
                [c.split("fld_")[1] for c in field_y.columns if c != "fld_"]
            )
        else:
            field_y = pd.DataFrame(index=df.index)
            cls._field_labels = []

        # ----- skills (multi-label) -----
        if "skills" in df:
            df["skills"] = _normalize_list_field(df["skills"])
        else:
            df["skills"] = [[] for _ in range(len(df))]

        all_skills = sorted({s for row in df["skills"] for s in row})
        if all_skills:
            mlb = MultiLabelBinarizer(classes=all_skills)
            skill_y_raw = mlb.fit_transform(df["skills"])
            skill_y = pd.DataFrame(
                skill_y_raw, columns=[f"sk_{s}" for s in mlb.classes_], index=df.index
            )
            cls._skill_labels = list(mlb.classes_)
        else:
            skill_y = pd.DataFrame(index=df.index)
            cls._skill_labels = []

        # ----- –∏—Ç–æ–≥–æ–≤–∞—è –º–∞—Ç—Ä–∏—Ü–∞ Y -----
        y = pd.concat([exp_y, fmt_y, field_y, skill_y], axis=1)

        # —É–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏, –≥–¥–µ –≤–µ–∑–¥–µ 0
        y = y.loc[:, y.sum(axis=0) > 0]

        cls._label_columns = list(y.columns)

        # ----- –æ–±—É—á–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω -----
        cls._pipeline = Pipeline([
            ("vect", TfidfVectorizer(ngram_range=(1, 3), max_features=8000)),
            ("clf", MultiOutputClassifier(
                LogisticRegression(max_iter=5000, class_weight="balanced")
            ))
        ])

        cls._pipeline.fit(df["text"], y)

    @classmethod
    def predict(cls, text: str) -> Dict[str, Any]:
        cls._train_if_needed()

        assert cls._pipeline is not None
        assert cls._label_columns is not None

        # ---- ML-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ----
        ml_pred = cls._pipeline.predict([text])[0]
        result_map = {col: int(ml_pred[i]) for i, col in enumerate(cls._label_columns)}

        # ---- –æ–ø—ã—Ç ----
        exp_found = []
        for col in cls._label_columns:
            if col.startswith("exp_") and result_map.get(col):
                exp_found.append(col.split("exp_")[1])
        exp_res = _heuristic_experience(text, exp_found)

        # ---- —Ñ–æ—Ä–º–∞—Ç ----
        fmt_found = []
        for col in cls._label_columns:
            if col.startswith("fmt_") and result_map.get(col):
                fmt_found.append(col.split("fmt_")[1])
        fmt_res = _heuristic_work_format(text, fmt_found)

        # ---- —Å—Ñ–µ—Ä–∞ ----
        field_found = []
        for col in cls._label_columns:
            if col.startswith("fld_") and result_map.get(col):
                field_found.append(col.split("fld_")[1])
        field_res = field_found[0] if field_found else "it"

        # ---- skills (–ø–æ ML) ----
        ml_skills = []
        for col in cls._label_columns:
            if col.startswith("sk_") and result_map.get(col):
                ml_skills.append(col.split("sk_")[1])

        # ---- skills (–ø–æ —Å–∏–Ω–æ–Ω–∏–º–∞–º) ----
        syn_skills = _extract_skills_by_synonyms(text)
        skills_res = sorted(set(ml_skills) | set(syn_skills))

        # ---- job_role: header + —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ ----
        job_smart = _extract_job_role_smart(text)
        if job_smart:
            job_role_res = job_smart
        else:
            job_role_res = _heuristic_job_role(text)

        # ---- salary ----
        salary_min, salary_max = _extract_salary(text)

        return {
            "job_role": job_role_res,
            "experience_level": exp_res,
            "work_format": fmt_res,
            "company_field": field_res,
            "skills": skills_res,
            "salary_min": salary_min,
            "salary_max": salary_max,
        }


# ============================================================
# 5. –í–ù–ï–®–ù–ò–ô –ò–ù–¢–ï–†–§–ï–ô–° (–¥–ª—è –±–æ—Ç–∞)
# ============================================================

def extract_vacancy_info(text: str) -> Dict[str, Any]:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –Ω–∞ –≤—Ö–æ–¥ —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏, –Ω–∞ –≤—ã—Ö–æ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—è."""
    return VacancyModel.predict(text)


def format_vacancy_result(v: Dict[str, Any]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram."""
    text = "üìÑ *–ê–Ω–∞–ª–∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏*\n\n"

    text += f"üíº –î–æ–ª–∂–Ω–æ—Å—Ç—å: {v.get('job_role', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞')}\n"
    text += f"üìä –£—Ä–æ–≤–µ–Ω—å: {v.get('experience_level', '–Ω–µ —É–∫–∞–∑–∞–Ω')}\n"
    text += f"üè¢ –§–æ—Ä–º–∞—Ç: {v.get('work_format', '–Ω–µ —É–∫–∞–∑–∞–Ω')}\n"
    text += f"üè≠ –°—Ñ–µ—Ä–∞: {v.get('company_field', '–Ω–µ —É–∫–∞–∑–∞–Ω–∞')}\n"

    skills = v.get("skills") or []
    if skills:
        text += f"üõ† –ù–∞–≤—ã–∫–∏: {', '.join(skills)}\n"
    else:
        text += "üõ† –ù–∞–≤—ã–∫–∏: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\n"

    smin = v.get("salary_min")
    smax = v.get("salary_max")
    if smin:
        if smax and smax != smin:
            text += f"üí∞ –ó–∞—Ä–ø–ª–∞—Ç–∞: {smin}‚Äì{smax} —Ä—É–±.\n"
        else:
            text += f"üí∞ –ó–∞—Ä–ø–ª–∞—Ç–∞: –æ—Ç {smin} —Ä—É–±.\n"
    else:
        text += "üí∞ –ó–∞—Ä–ø–ª–∞—Ç–∞: –Ω–µ —É–∫–∞–∑–∞–Ω–∞\n"

    return text

